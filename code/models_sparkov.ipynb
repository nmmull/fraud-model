{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18577425",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fraudTrain.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df_train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfraudTrain.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m df_test = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mfraudTest.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# data preprocessing plus exploratory data analysis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Detection/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Detection/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Detection/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Detection/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Detection/venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'fraudTrain.csv'"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/kartik2112/fraud-detection?select=fraudTrain.csv\n",
    "# dataset preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_train = pd.read_csv(\"fraudTrain.csv\")\n",
    "df_test = pd.read_csv(\"fraudTest.csv\")\n",
    "\n",
    "# data preprocessing plus exploratory data analysis\n",
    "def preprocess(df):\n",
    "    # combine first and last name to one column\n",
    "    #df['name'] = df['first'] + df['last']\n",
    "    df = df.drop(columns=['first','last'])\n",
    "\n",
    "    # combine address into\n",
    "\n",
    "    # drop time, also drop data for a baseline test (can manipulate what data to add back in later)\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "    df = df.sort_values(by=\"trans_date_trans_time\", ascending=True)\n",
    "    df = df.drop(columns=['trans_date_trans_time', 'job', 'dob', 'unix_time', 'city_pop', 'category', 'street', 'city', 'state', 'zip'\n",
    "                          , 'gender', 'cc_num', 'trans_num'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = preprocess(df_train)\n",
    "df_test = preprocess(df_test)\n",
    "\n",
    "# training data\n",
    "X_training = df_train.drop('is_fraud', axis=1)\n",
    "y_training = df_train['is_fraud']\n",
    "\n",
    "# testing data\n",
    "X_test = df_test.drop('is_fraud', axis=1)\n",
    "y_test = df_test['is_fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding for categorical data\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('merchants', OneHotEncoder(handle_unknown='ignore'), ['merchant'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ct.fit(X_training)\n",
    "\n",
    "X_training_ohe = ct.transform(X_training)\n",
    "X_testing_ohe  = ct.transform(X_test)\n",
    "print(ct.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e106a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       1.00      0.55      0.71    553574\n",
      "       fraud       0.01      0.77      0.01      2145\n",
      "\n",
      "    accuracy                           0.55    555719\n",
      "   macro avg       0.50      0.66      0.36    555719\n",
      "weighted avg       0.99      0.55      0.71    555719\n",
      "\n",
      "PRAUC:  0.00910538255392279\n",
      "              Predicted Legit  Predicted Fraud\n",
      "Actual Legit           304399           249175\n",
      "Actual Fraud              498             1647\n"
     ]
    }
   ],
   "source": [
    "# logistic regression model\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# use balanced to let the model increase weighting for fraud cases\n",
    "logistic_regression = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=10000,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "logistic_regression.fit(X_training_ohe, y_training)\n",
    "lr_pred = logistic_regression.predict(X_testing_ohe)\n",
    "\n",
    "# manipulating the threshold (threshold here is set to get some amount in each category of confusion matrix)\n",
    "lr_prob = logistic_regression.predict_proba(X_testing_ohe)[:, 1]\n",
    "threshold = 0.4\n",
    "lr_pred = (lr_prob >= threshold).astype(int)\n",
    "\n",
    "# print results\n",
    "target_names = [\"legit\", \"fraud\"]\n",
    "print(classification_report(y_test, lr_pred, target_names=target_names, zero_division=0))\n",
    "print(\"PRAUC: \", average_precision_score(y_test, lr_prob))\n",
    "\n",
    "cm = confusion_matrix(y_test,lr_pred)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Actual Legit\", \"Actual Fraud\"],\n",
    "    columns=[\"Predicted Legit\", \"Predicted Fraud\"]\n",
    ")\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da464db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       1.00      0.76      0.86    553574\n",
      "       fraud       0.01      0.60      0.02      2145\n",
      "\n",
      "    accuracy                           0.76    555719\n",
      "   macro avg       0.50      0.68      0.44    555719\n",
      "weighted avg       0.99      0.76      0.86    555719\n",
      "\n",
      "PRAUC:  0.009063840551307855\n",
      "              Predicted Legit  Predicted Fraud\n",
      "Actual Legit           421531           132043\n",
      "Actual Fraud              850             1295\n"
     ]
    }
   ],
   "source": [
    "# SVM model\n",
    "# have to use linearSVM because SVM scales horribly with this dataset\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "svm = LinearSVC(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=10000,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "svm.fit(X_training_ohe, y_training)\n",
    "svm_pred = svm.predict(X_testing_ohe)\n",
    "\n",
    "# manipulating the threshold (threshold here is set to get some amount in each category of confusion matrix)\n",
    "decision_scores = svm.decision_function(X_testing_ohe)\n",
    "threshold = 0.2 \n",
    "svm_pred = (decision_scores >= threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names, zero_division=0))\n",
    "print(\"PRAUC: \", average_precision_score(y_test, decision_scores))\n",
    "\n",
    "cm_svm = confusion_matrix(y_test, svm_pred)\n",
    "cm_svm_df = pd.DataFrame(\n",
    "    cm_svm,\n",
    "    index=[\"Actual Legit\", \"Actual Fraud\"],\n",
    "    columns=[\"Predicted Legit\", \"Predicted Fraud\"]\n",
    ")\n",
    "\n",
    "print(cm_svm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d678210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       1.00      0.79      0.88    553574\n",
      "       fraud       0.01      0.56      0.02      2145\n",
      "\n",
      "    accuracy                           0.79    555719\n",
      "   macro avg       0.50      0.67      0.45    555719\n",
      "weighted avg       0.99      0.79      0.88    555719\n",
      "\n",
      "PRAUC:  0.009030535032463377\n",
      "              Predicted Legit  Predicted Fraud\n",
      "Actual Legit           435305           118269\n",
      "Actual Fraud              938             1207\n"
     ]
    }
   ],
   "source": [
    "# neural network (multilayer perceptron) (~2 min to run)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# baseline hyperparameters,\n",
    "mlp = make_pipeline(StandardScaler(with_mean=False), MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64), # larger dataset requires more nodes in each layer\n",
    "    activation='relu',            \n",
    "    solver='adam',\n",
    "    alpha = 0.001,               \n",
    "    max_iter=500,        \n",
    "    random_state=0,\n",
    "))\n",
    "\n",
    "mlp.fit(X_training_ohe, y_training)\n",
    "mlp_pred = mlp.predict(X_testing_ohe)\n",
    "\n",
    "mlp_prob = mlp.predict_proba(X_testing_ohe)[:, 1]\n",
    "\n",
    "# manipulating the threshold (threshold here is set to get some amount in each category of confusion matrix)\n",
    "# 0.05 and above results in model not finding anything\n",
    "threshold = 0.01\n",
    "mlp_pred = (mlp_prob >= threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_test, mlp_pred, target_names=target_names, zero_division=0))\n",
    "print(\"PRAUC: \", average_precision_score(y_test, mlp_prob))\n",
    "\n",
    "cm_mlp = confusion_matrix(y_test, mlp_pred)\n",
    "cm_mlp_df = pd.DataFrame(\n",
    "    cm_mlp,\n",
    "    index=[\"Actual Legit\", \"Actual Fraud\"],\n",
    "    columns=[\"Predicted Legit\", \"Predicted Fraud\"]\n",
    ")\n",
    "\n",
    "print(cm_mlp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c19aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       1.00      0.19      0.33    553574\n",
      "       fraud       0.00      0.93      0.01      2145\n",
      "\n",
      "    accuracy                           0.20    555719\n",
      "   macro avg       0.50      0.56      0.17    555719\n",
      "weighted avg       0.99      0.20      0.32    555719\n",
      "\n",
      "PRAUC:  0.008352688758024767\n",
      "              Predicted Legit  Predicted Fraud\n",
      "Actual Legit           107595           445979\n",
      "Actual Fraud              151             1994\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "num_pos = y_training.sum()\n",
    "num_neg = len(y_training) - num_pos\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=500,  \n",
    "    max_depth=5,        \n",
    "    learning_rate=0.05, \n",
    "    subsample=0.8,      \n",
    "    colsample_bytree=0.8, \n",
    "    random_state=0,\n",
    "    tree_method='hist', \n",
    "    scale_pos_weight=num_neg /num_pos, # balance the classes to have more weight on fraud cases\n",
    ")\n",
    "\n",
    "xgb.fit(X_training_ohe, y_training)\n",
    "xgb_pred = xgb.predict(X_testing_ohe)\n",
    "\n",
    "xgb_prob = xgb.predict_proba(X_testing_ohe)[:, 1]\n",
    "\n",
    "# manipulating the threshold (threshold here is set to get some amount in each category of confusion matrix)\n",
    "threshold = 0.4\n",
    "xgb_pred = (xgb_prob >= threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_test, xgb_pred, target_names=target_names, zero_division=0))\n",
    "print(\"PRAUC: \", average_precision_score(y_test, xgb_prob))\n",
    "\n",
    "cm_xgb = confusion_matrix(y_test, xgb_pred)\n",
    "cm_xgb_df = pd.DataFrame(\n",
    "    cm_xgb,\n",
    "    index=[\"Actual Legit\", \"Actual Fraud\"],\n",
    "    columns=[\"Predicted Legit\", \"Predicted Fraud\"]\n",
    ")\n",
    "\n",
    "print(cm_xgb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c88a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       legit       1.00      0.01      0.01    553574\n",
      "       fraud       0.00      1.00      0.01      2145\n",
      "\n",
      "    accuracy                           0.01    555719\n",
      "   macro avg       0.50      0.50      0.01    555719\n",
      "weighted avg       0.99      0.01      0.01    555719\n",
      "\n",
      "PRAUC:  0.008063305459718513\n",
      "              Predicted Legit  Predicted Fraud\n",
      "Actual Legit             4161           549413\n",
      "Actual Fraud                5             2140\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (~1-2 min)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500, \n",
    "    min_samples_split=2,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    max_depth=15\n",
    ")\n",
    "\n",
    "# baseline test\n",
    "rf.fit(X_training_ohe, y_training)\n",
    "rf_pred = rf.predict(X_testing_ohe)\n",
    "\n",
    "# manipulating the threshold (threshold here is set to get some amount in each category of confusion matrix)\n",
    "rf_prob = rf.predict_proba(X_testing_ohe)[:, 1]\n",
    "threshold = 0.45\n",
    "rf_pred = (rf_prob >= threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_test, rf_pred, target_names=target_names, zero_division=0))\n",
    "print(\"PRAUC: \", average_precision_score(y_test, rf_prob))\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, rf_pred)\n",
    "cm_rf_df = pd.DataFrame(\n",
    "    cm_rf,\n",
    "    index=[\"Actual Legit\", \"Actual Fraud\"],\n",
    "    columns=[\"Predicted Legit\", \"Predicted Fraud\"]\n",
    ")\n",
    "\n",
    "print(cm_rf_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
